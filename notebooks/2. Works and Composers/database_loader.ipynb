{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#database connection settings\n",
    "import psycopg2\n",
    "\n",
    "db_name = \"traviato_development\"\n",
    "db_host = \"localhost\"\n",
    "db_port = \"5432\"\n",
    "db_user = \"lievgarcia\"\n",
    "db_pwd = \"traviato81\"\n",
    "\n",
    "conn = psycopg2.connect(database=db_name, user=db_user, password=db_pwd, host=db_host, port=db_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPOSERS LOADING\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../data/processed/composers/wikipedia.csv', index_col=0)\n",
    "\n",
    "cursor = conn.cursor()\n",
    "for idx,row in df.iterrows():\n",
    "    insert = 'INSERT INTO COMPOSERS (NAME, COUNTRY, URL, URI) VALUES ('\n",
    "    values = \"'\" + row['composer'].replace(\"'\", \"''\") + \"', '\" + row['country'].replace(\"'\", \"''\") + \"', '\" + row['composer_url'] + \"', '\" + row['composer_key'] + \"'); \"\n",
    "    commit = 'COMMIT;'    \n",
    "#     print(insert + values + commit)\n",
    "    cursor.execute(insert + values + commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPOSERS LOADING\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../data/processed/composers/wikipedia.csv', index_col=0)\n",
    "\n",
    "cursor = conn.cursor()\n",
    "for idx,row in df.iterrows():\n",
    "    insert = 'INSERT INTO COMPOSERS (NAME, COUNTRY, URL, URI) VALUES ('\n",
    "    values = \"'\" + row['composer'].replace(\"'\", \"''\") + \"', '\" + row['country'].replace(\"'\", \"''\") + \"', '\" + row['composer_url'] + \"', '\" + row['composer_key'] + \"'); \"\n",
    "    commit = 'COMMIT;'    \n",
    "    print(insert + values + commit)\n",
    "    cursor.execute(insert + values + commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 6.0; WOW64; rv:24.0) Gecko/20100101 Firefox/24.0' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cw_df = pd.read_csv('../../data/processed/works/wikipedia.csv', index_col=0)\n",
    "cwm_df = pd.read_csv('../../data/processed/works/more_works.csv', index_col=0)\n",
    "cwm_df['composer_url'] = '/'\n",
    "cwm_df['composer_key'] = cwm_df.apply(lambda row: row['composer_url'].split('/')[-1], axis=1)\n",
    "cwm_df['work_key'] = cwm_df.apply(lambda row: row['work_url'].split('/')[-1], axis=1)\n",
    "cwm_df = cwm_df.replace(np.nan, '', regex=True)\n",
    "\n",
    "cwm_df = cwm_df.merge(cw_df, left_on=['work_key'], right_on=['work_key'], how='left')\n",
    "cwm_df = cwm_df[['composer_y', 'work_y', 'composer_url_y', 'work_url_x', 'composer_key_y', 'work_key']]\n",
    "cwm_df = cwm_df.rename(index=str, columns={\"composer_y\": \"composer\", \"work_y\": \"work\", \"composer_url_y\": \"composer_url\", \"work_url_x\": \"work_url\", \"composer_key_y\": \"composer_key\"})\n",
    "\n",
    "#There are records that have not been matched and need to be updated before loading\n",
    "miss_df = cwm_df[cwm_df['composer'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Match missing works to their composers before concatenating.\n",
    "import pandas as pd\n",
    "\n",
    "cursor = conn.cursor()  \n",
    "cursor.execute(\"SELECT distinct name, url, uri FROM composers c\")\n",
    "comp_df = pd.DataFrame(cursor.fetchall(), columns=['name', 'url', 'uri'])\n",
    "\n",
    "for idx,row in miss_df.iterrows():    \n",
    "    url = row['work_url']\n",
    "    r  = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(r.text, \"html5lib\")\n",
    "    try:\n",
    "        result = soup.find(attrs={'id': 'P86'}).find(attrs={'class': 'wikibase-snakview-value wikibase-snakview-variation-valuesnak'})\n",
    "        composer_key = ''\n",
    "        composer_key = result.find('a').get('title')\n",
    "        composer_url = 'http://www.wikidata.org/wiki/' + composer_key\n",
    "        composer_r  = requests.get(composer_url, headers=headers)\n",
    "        composer_soup = BeautifulSoup(composer_r.text, \"html5lib\")    \n",
    "        composer_name = composer_soup.find(attrs={'class': 'wikibase-title-label'}).get_text()        \n",
    "        work_name = soup.find(attrs={'class': 'wikibase-title-label'}).get_text()     \n",
    "        if comp_df[comp_df['uri']==composer_key].shape[0] != 0:\n",
    "            row['composer'] = result.find('a').get_text()\n",
    "            row['composer_url'] = composer_url\n",
    "            row['composer_key'] = composer_key\n",
    "            row['work'] = work_name\n",
    "        else:\n",
    "            insert = 'INSERT INTO COMPOSERS (NAME, URL, URI) VALUES ('\n",
    "            values = \"'\" + composer_name + \"', '\" + composer_url + \"', '\" + composer_key + \"'); \"\n",
    "            commit = 'COMMIT;'\n",
    "            print(insert + values + commit)            \n",
    "    except:\n",
    "        if row['work_url'] == 'http://www.wikidata.org/wiki/Q7144946':\n",
    "            row['composer'] = 'Paula M. Kimper'\n",
    "            row['composer_url'] = 'http://www.wikidata.org/wiki/P000001'\n",
    "            row['composer_key'] = 'P000001'\n",
    "            row['work'] = 'Patience and Sarah'            \n",
    "        else:\n",
    "            print(composer_key + '---' + url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3976, 6)\n",
      "(599, 6)\n",
      "(501, 6)\n",
      "(98, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4575, 6)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_df = cwm_df[~cwm_df['composer'].isna()]\n",
    "\n",
    "print(cw_df.shape)\n",
    "print(cwm_df.shape)\n",
    "print(mapped_df.shape)\n",
    "print(miss_df.shape)\n",
    "\n",
    "#Concatenate all mapped works into one DF\n",
    "ref_df = pd.concat([cw_df, mapped_df, miss_df])\n",
    "ref_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WORKS LOADING\n",
    "import pandas as pd\n",
    "\n",
    "cursor = conn.cursor()\n",
    "for idx,row in ref_df.iterrows():\n",
    "    insert = 'INSERT INTO WORKS (NAME, URL, URI, COMPOSER_URI) VALUES ('\n",
    "    values = \"'\" + row['work'].replace(\"'\", \"''\") + \"', '\" + row['work_url'] + \"', '\" + row['work_key'] + \"', '\" + row['composer_key'] + \"'); \"\n",
    "    commit = 'COMMIT;'    \n",
    "#     print(insert + values + commit)\n",
    "    cursor.execute(insert + values + commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPERA AMERICA LOADER\n",
    "import pandas as pd\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "lt_df = pd.read_csv('../../data/processed/listings/operaamerica.csv', index_col=0)\n",
    "lt_df['composer'] = lt_df.apply(lambda row: row['composer'].replace(u'\\xa0', '---'), axis=1)\n",
    "\n",
    "for idx,row in lt_df.iterrows():\n",
    "    insert = 'INSERT INTO LISTINGS (SOURCE_ID, COMPOSER, WORK, ADDITIONAL_TEXT) VALUES ('\n",
    "    values = \"1, '\" + row['composer'].replace(\"'\", \"''\") + \"', '\" + row['work'].replace(\"'\", \"''\") + \"', '\" + row['date'] + \"'); \"\n",
    "    commit = 'COMMIT;'    \n",
    "#     print(insert + values + commit)\n",
    "    cursor.execute(insert + values + commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPERA AMERICA MAPPINGS\n",
    "import pandas as pd\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "lt_df = pd.read_csv('../../data/processed/mapping/operaamerica.csv', index_col=0)\n",
    "# lt_df.head()\n",
    "for idx,row in lt_df.iterrows():\n",
    "    insert = 'INSERT INTO LISTING_MAPPERS (SOURCE_ID, LISTING_COMPOSER, LISTING_WORK, WORK_URI) VALUES ('\n",
    "    values = \"1, '\" + row['composer_x'].replace(\"'\", \"''\") + \"', '\" + row['work_x'].replace(\"'\", \"''\") + \"', '\" + row['work_key'] + \"'); \"\n",
    "    commit = 'COMMIT;'    \n",
    "#     print(insert + values + commit)\n",
    "    cursor.execute(insert + values + commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#METROPOLITAN OPERA LOADER\n",
    "import pandas as pd\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "lt_df = pd.read_csv('../../data/processed/listings/metropolitan_opera.csv', index_col=0)\n",
    "lt_df['composer'] = ''\n",
    "\n",
    "\n",
    "for idx,row in lt_df.iterrows():\n",
    "    insert = 'INSERT INTO LISTINGS (SOURCE_ID, COMPOSER, WORK, ADDITIONAL_TEXT) VALUES ('\n",
    "    values = \"2, '\" + row['composer'].replace(\"'\", \"''\") + \"', '\" + row['work'].replace(\"'\", \"''\") + \"', '\" + row['date'] + \"'); \"\n",
    "    commit = 'COMMIT;'    \n",
    "#     print(insert + values + commit)\n",
    "    cursor.execute(insert + values + commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUSSTAGE OPERA LOADER\n",
    "import pandas as pd\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "lt_df = pd.read_csv('../../data/processed/listings/ausstage.csv', index_col=0)\n",
    "lt_df['composer'] = ''\n",
    "\n",
    "\n",
    "for idx,row in lt_df.iterrows():\n",
    "    insert = 'INSERT INTO LISTINGS (SOURCE_ID, COMPOSER, WORK, ADDITIONAL_TEXT) VALUES ('\n",
    "    values = \"3, '\" + row['composer'].replace(\"'\", \"''\") + \"', '\" + row['Work'].replace(\"'\", \"''\") + \"', '\" + row['date'] + \"'); \"\n",
    "    commit = 'COMMIT;'    \n",
    "#     print(insert + values + commit)\n",
    "    cursor.execute(insert + values + commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BACKTRACK OPERA LOADER\n",
    "import pandas as pd\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "lt_df = pd.read_csv('../../data/processed/listings/bachtrack.csv', index_col=0)\n",
    "\n",
    "for idx,row in lt_df.iterrows():\n",
    "    insert = 'INSERT INTO LISTINGS (SOURCE_ID, COMPOSER, WORK, ADDITIONAL_TEXT) VALUES ('\n",
    "    values = \"4, '\" + row['composer'].replace(\"'\", \"''\") + \"', '\" + row['work'].replace(\"'\", \"''\") + \"', '\" + row['date'] + \"'); \"\n",
    "    commit = 'COMMIT;'    \n",
    "#     print(insert + values + commit)\n",
    "    cursor.execute(insert + values + commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONCERT DIARY LOADER\n",
    "import pandas as pd\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "lt_df = pd.read_csv('../../data/processed/listings/concert_diary.csv', index_col=0)\n",
    "lt_df['composer'] = lt_df.apply(lambda row: row['composer'].replace(u'\\xa0', '---'), axis=1)\n",
    "\n",
    "for idx,row in lt_df.iterrows():\n",
    "    insert = 'INSERT INTO LISTINGS (SOURCE_ID, COMPOSER, WORK, ADDITIONAL_TEXT) VALUES ('\n",
    "    values = \"5, '\" + row['composer'].replace(\"'\", \"''\") + \"', '\" + row['work'].replace(\"'\", \"''\") + \"', '\" + row['date'] + \"'); \"\n",
    "    commit = 'COMMIT;'    \n",
    "#     print(insert + values + commit)\n",
    "    cursor.execute(insert + values + commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NADAC LOADER\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "lt_df = pd.read_csv('../../data/processed/listings/nadac.csv', index_col=0)\n",
    "lt_df['composer'] = ''\n",
    "lt_df = lt_df.replace(np.nan, '', regex=True)\n",
    "\n",
    "for idx,row in lt_df.iterrows():\n",
    "    insert = 'INSERT INTO LISTINGS (SOURCE_ID, COMPOSER, WORK, ADDITIONAL_TEXT) VALUES ('\n",
    "    values = \"6, '\" + row['composer'].replace(\"'\", \"''\") + \"', '\" + row['TITLE'].replace(\"'\", \"''\") + \"', '\" + str(row['NPERFORM']) + \"'); \"\n",
    "    commit = 'COMMIT;'    \n",
    "#     print(insert + values + commit)\n",
    "    cursor.execute(insert + values + commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPERA SCOTLAND LOADER\n",
    "import pandas as pd\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "lt_df = pd.read_csv('../../data/processed/listings/opera_scotland.csv', index_col=0)\n",
    "lt_df = lt_df.replace(np.nan, '', regex=True)\n",
    "\n",
    "# lt_df.shape\n",
    "for idx,row in lt_df.iterrows():\n",
    "    insert = 'INSERT INTO LISTINGS (SOURCE_ID, COMPOSER, WORK, ADDITIONAL_TEXT) VALUES ('\n",
    "    values = \"7, '\" + row['composer'].replace(\"'\", \"''\") + \"', '\" + row['work'].replace(\"'\", \"''\") + \"', '\" + row['date'] + \"'); \"\n",
    "    commit = 'COMMIT;'    \n",
    "#     print(insert + values + commit)\n",
    "    cursor.execute(insert + values + commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#OPERABASE LOADER\n",
    "import pandas as pd\n",
    "\n",
    "def fix_encoding(string):\n",
    "    try:\n",
    "        string = string.encode(encoding='mac_roman').decode('utf-8')        \n",
    "    except:\n",
    "        None\n",
    "    \n",
    "    return string\n",
    "\n",
    "lt_df = pd.read_csv('../../data/processed/listings/operabase.csv', index_col=0)\n",
    "lt_df = lt_df.replace(np.nan, '', regex=True)\n",
    "lt_df['work'] = lt_df.apply(lambda row: fix_encoding(row['work']), axis=1)\n",
    "lt_df['composer'] = ''\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for idx,row in lt_df.iterrows():\n",
    "    insert = 'INSERT INTO LISTINGS (SOURCE_ID, COMPOSER, WORK, ADDITIONAL_TEXT) VALUES ('\n",
    "    values = \"8, '\" + row['composer'].replace(\"'\", \"''\") + \"', '\" + row['work'].replace(\"'\", \"''\") + \"', '\" + str(row['date']) + \"'); \"\n",
    "    commit = 'COMMIT;'    \n",
    "#     print(insert + values + commit)\n",
    "    cursor.execute(insert + values + commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROYAL OPERA HOUSE  LOADER\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "lt_df = pd.read_csv('../../data/processed/listings/royal_opera_house.csv', index_col=0)\n",
    "lt_df = lt_df.replace(np.nan, '', regex=True)\n",
    "\n",
    "# lt_df.head()\n",
    "for idx,row in lt_df.iterrows():\n",
    "    insert = 'INSERT INTO LISTINGS (SOURCE_ID, COMPOSER, WORK, ADDITIONAL_TEXT) VALUES ('\n",
    "    values = \"9, '\" + row['composer'].replace(\"'\", \"''\") + \"', '\" + row['work'].replace(\"'\", \"''\") + \"', '\" + row['date'] + \"'); \"\n",
    "    commit = 'COMMIT;'    \n",
    "#     print(insert + values + commit)\n",
    "    cursor.execute(insert + values + commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEATRO ALLA SCALA LOADER\n",
    "import pandas as pd\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "lt_df = pd.read_csv('../../data/processed/listings/teatro_all_scala.csv', index_col=0)\n",
    "lt_df = lt_df.replace(np.nan, '', regex=True)\n",
    "\n",
    "# lt_df.head()\n",
    "for idx,row in lt_df.iterrows():\n",
    "    insert = 'INSERT INTO LISTINGS (SOURCE_ID, COMPOSER, WORK, ADDITIONAL_TEXT) VALUES ('\n",
    "    values = \"10, '\" + row['composer'].replace(\"'\", \"''\") + \"', '\" + row['work'].replace(\"'\", \"''\") + \"', '\" + row['date'] + \"'); \"\n",
    "    commit = 'COMMIT;'    \n",
    "#     print(insert + values + commit)\n",
    "    cursor.execute(insert + values + commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UKTW LOADER\n",
    "import pandas as pd\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "lt_df = pd.read_csv('../../data/processed/listings/uk_theatreweb.csv', index_col=0)\n",
    "lt_df = lt_df.replace(np.nan, '', regex=True)\n",
    "\n",
    "# lt_df.head()\n",
    "for idx,row in lt_df.iterrows():\n",
    "    insert = 'INSERT INTO LISTINGS (SOURCE_ID, COMPOSER, WORK, ADDITIONAL_TEXT) VALUES ('\n",
    "    values = \"11, '\" + row['composer'].replace(\"'\", \"''\") + \"', '\" + row['work'].replace(\"'\", \"''\") + \"', '\" + row['date_from'] + \"'); \"\n",
    "    commit = 'COMMIT;'    \n",
    "#     print(insert + values + commit)\n",
    "    cursor.execute(insert + values + commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UKTW LOADER\n",
    "import pandas as pd\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "lt_df = pd.read_csv('../../data/processed/listings/uk_theatreweb.csv', index_col=0) \n",
    "lt_df = lt_df.replace(np.nan, '', regex=True)\n",
    "\n",
    "# lt_df.head()\n",
    "for idx,row in lt_df.iterrows():\n",
    "    insert = 'INSERT INTO LISTINGS (SOURCE_ID, COMPOSER, WORK, ADDITIONAL_TEXT) VALUES ('\n",
    "    values = \"11, '\" + row['composer'].replace(\"'\", \"''\") + \"', '\" + row['work'].replace(\"'\", \"''\") + \"', '\" + str(row['num_performances']) + \"'); \"\n",
    "    commit = 'COMMIT;'    \n",
    "#     print(insert + values + commit)\n",
    "    cursor.execute(insert + values + commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VIENNA OPERA HOUSE LOADER\n",
    "import pandas as pd\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "lt_df = pd.read_csv('../../data/processed/listings/vienna_opera.csv', index_col=0) \n",
    "lt_df = lt_df.replace(np.nan, '', regex=True)\n",
    "lt_df['composer'] = ''\n",
    "\n",
    "# lt_df.head()\n",
    "for idx,row in lt_df.iterrows():\n",
    "    insert = 'INSERT INTO LISTINGS (SOURCE_ID, COMPOSER, WORK, ADDITIONAL_TEXT) VALUES ('\n",
    "    values = \"12, '\" + row['composer'].replace(\"'\", \"''\") + \"', '\" + row['work'].replace(\"'\", \"''\") + \"', '\" + row['date'] + \"'); \"\n",
    "    commit = 'COMMIT;'    \n",
    "#     print(insert + values + commit)\n",
    "    cursor.execute(insert + values + commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
