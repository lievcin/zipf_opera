{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests, csv, string, re, datetime\n",
    "from csv import writer\n",
    "import time\n",
    "import random\n",
    "\n",
    "headers = { 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36'}\n",
    "cookies = dict(PHPSESSID='hu3bbnbkj9pjhm2h5ls52r5aa0', collections='audio_tech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [['https://web.archive.org/web/20120510091223/http://operabase.com/plan.cgi?lang=en&season=2011/12', \n",
    " 'https://web.archive.org/web/20120510091223/http://operabase.com/', '1112', 3],\n",
    "['https://web.archive.org/web/20130223084132/http://www.operabase.com/plan.cgi?lang=en&season=2012/13', \n",
    " 'https://web.archive.org/web/20130223084132/http://www.operabase.com/', '1213', 1],\n",
    "['https://web.archive.org/web/20140729224252/http://operabase.com:80/plan.cgi?lang=en&season=2013/14', \n",
    "            'https://web.archive.org/web/20140729224252/http://operabase.com:80/', '1314', 2],\n",
    "['https://web.archive.org/web/20150924162245/http://operabase.com:80/plan.cgi?lang=en&season=2014/15', \n",
    "            'https://web.archive.org/web/20150924162245/http://operabase.com:80/', '1415', 1],\n",
    "['https://web.archive.org/web/20160307032948/http://operabase.com/plan.cgi?lang=en&season=2015/16', \n",
    "            'https://web.archive.org/web/20160307032948/http://operabase.com/', '1516', 1],\n",
    "['http://operabase.com/plan.cgi?lang=en&season=2016/17', 'http://operabase.com/', '1617', 1],\n",
    "['http://operabase.com/plan.cgi?lang=en&season=2017/18', 'http://operabase.com/', '1718', 1],\n",
    "['http://operabase.com/plan.cgi?lang=en&season=2018/19', 'http://operabase.com/', '1819', 1]]\n",
    "\n",
    "#0,1,2,3,4,5,6,7\n",
    "season_index=4\n",
    "\n",
    "arch_url=links[season_index][0]\n",
    "archbase_url=links[season_index][1]\n",
    "season=links[season_index][2]\n",
    "offset=links[season_index][3]\n",
    "\n",
    "r  = requests.get(arch_url, headers=headers)\n",
    "soup = BeautifulSoup(r.text, \"html5lib\")    \n",
    "countries =[]\n",
    "\n",
    "for l in soup.select('table a'):\n",
    "    if 'plan.cgi?lang=en&season=' in l.get('href') and '&ci=':\n",
    "        country = []\n",
    "        country.append(l.text)\n",
    "        country.append(l.get('href'))        \n",
    "        countries.append(country)\n",
    "\n",
    "listings = []\n",
    "countries = countries[offset:]\n",
    "processed_countries=[]\n",
    "processed_keys=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "#######save the pages as scraping the site is better done locally.#######\n",
    "#########################################################################\n",
    "\n",
    "import os\n",
    "\n",
    "for i in range(100):\n",
    "    for c in countries:\n",
    "        url = archbase_url + c[1]\n",
    "        country = c[0]\n",
    "        abbr=c[1].split(\"=\")[-1]\n",
    "        if abbr not in processed_countries:\n",
    "            try:\n",
    "                r  = requests.get(url, headers=headers)\n",
    "                soup = BeautifulSoup(r.text, \"html5lib\")\n",
    "                #########save the country file#########\n",
    "                with open(\"../../data/raw/operabase_html/\" + season + \"/\" + abbr + \".html\", \"w\") as file:\n",
    "                    file.write(str(soup))   \n",
    "                    \n",
    "                #########theatre schedules#########\n",
    "        #         time.sleep(random.random())\n",
    "                schedules = soup.find_all('a')\n",
    "                schedules = [s for s in schedules if 'view.cgi?lang=en&cal=' in s.get('href')]\n",
    "                print\n",
    "                for schedule in schedules:\n",
    "                    cal_url = schedule.get('href')\n",
    "                    filename=\"../../data/raw/operabase_html/\" + season + \"/\" + cal_url.strip() + \".html\"\n",
    "                    if os.path.exists(filename)==False:\n",
    "#                         print\n",
    "                        if cal_url.split(\"=\")[-1] not in processed_keys:                       \n",
    "#                             time.sleep(2*random.random())\n",
    "                            r  = requests.get(archbase_url + cal_url, headers=headers)\n",
    "                            cal_soup = BeautifulSoup(r.text, \"html5lib\")            \n",
    "\n",
    "                            with open(\"../../data/raw/operabase_html/\" + season + \"/\" + cal_url.strip() + \".html\", \"w\") as file:\n",
    "                                file.write(str(cal_soup))                        \n",
    "                            processed_keys.append(cal_url.split(\"=\")[-1])                \n",
    "            #         print(schedules)            \n",
    "                processed_countries.append(abbr)\n",
    "            except:\n",
    "                None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season: 1112\n",
      "Season: 1213\n",
      "Season: 1314\n",
      "Season: 1415\n",
      "Season: 1516\n",
      "Season: 1617\n",
      "Season: 1718\n",
      "Season: 1819\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "seasons=['1112','1213','1314','1415','1516','1617','1718','1819']\n",
    "country_dict = { \n",
    "    'al':'Albania', 'am':'Armenia', 'at':'Austria', 'az':'Azerbaijan', 'ba':'Bosnia-Herzegovina', 'be':'Belgium',\n",
    "    'bg':'Bulgaria', 'by':'Belarus', 'ca':'Canada', 'ch':'Switzerland', 'cl':'Chile','cz':'Czech Republic',\n",
    "    'de':'Germany', 'dk':'Denmark', 'ee':'Estonia', 'eg':'Egypt', 'es':'Spain', 'fi':'Finland', 'fr':'France',\n",
    "    'ge':'Georgia', 'gr':'Greece', 'hr':'Croatia', 'hu':'Hungary', 'ie':'Ireland', 'il':'Israel', 'is':'Iceland',\n",
    "    'it':'Italy', 'jp':'Japan', 'kg':'Kyrgyzstan', 'kr':'South Korea', 'kz':'Kazakhstan', 'lt':'Lithuania',\n",
    "    'lu':'Luxembourg', 'lv':'Latvia', 'mc':'Monaco', 'md':'Moldova', 'mk':'Macedonia', 'mn':'Mongolia', 'mt':'Malta',\n",
    "    'mx':'Mexico', 'nl':'Netherlands', 'no':'Norway', 'om':'Oman', 'pe':'Peru', 'pl':'Poland', 'pt':'Portugal', \n",
    "    'ro':'Romania', 'rs':'Serbia', 'ru':'Russia', 'se':'Sweden', 'sg':'Singapore', 'si':'Slovenia', 'sk':'Slovakia', \n",
    "    'sr':'Serbia',  'th':'Thailand', 'tr':'Turkey', 'ua':'Ukraine', 'uk':'United Kingdom', 'us':'United States', \n",
    "    'uz':'Uzbekistan', 'za':'South Africa'\n",
    "}\n",
    "# seasons=['1112']\n",
    "\n",
    "listings=[]\n",
    "\n",
    "for season in seasons:\n",
    "    files = glob.glob(\"../../data/raw/operabase_html/\" + season + \"/\" + '*.html')\n",
    "    files = [f for f in files if 'lang' not in f]\n",
    "#     files= ['../../data/raw/operabase_html/1112/at.html']\n",
    "           \n",
    "    print('Season: ' + season)\n",
    "#     print(files)\n",
    "    for file in files:\n",
    "        \n",
    "        if country_dict.get(file[:-5].split('/')[-1]):\n",
    "            country = country_dict.get(file[:-5].split('/')[-1])\n",
    "        else:\n",
    "            print('Missing key: ' + file[:-5].split('/')[-1])        \n",
    "        \n",
    "        with open(file, encoding=\"utf-8\") as f:\n",
    "            data = f.read()\n",
    "            soup = BeautifulSoup(data, 'html.parser')            \n",
    "        schedules = soup.find_all('a')\n",
    "        schedules = [s for s in schedules if 'view.cgi?lang=en&cal=' in s.get('href')]        \n",
    "        \n",
    "        for idx,schedule in enumerate(schedules):\n",
    "            map_dict = {}        \n",
    "            try:\n",
    "                items = schedule.next_sibling.next_sibling.find_all('a')\n",
    "                par_item = schedule.next_sibling.next_sibling                               \n",
    "                    \n",
    "                for item in items:\n",
    "                    work = item.get_text()\n",
    "                    composer = re.search('\\((.*?)\\)', item.parent.next_sibling).group(0)[1:-1]\n",
    "                    map_dict[work]=composer          \n",
    "\n",
    "            except:\n",
    "                None\n",
    "\n",
    "            city = schedule.previous_sibling.previous_sibling.find('b').text\n",
    "            theatre = ','.join(schedule.previous_sibling.previous_sibling.text.split(',')[1:]).strip()        \n",
    "            url_cal = \"../../data/raw/operabase_html/\" + season + \"/\" + schedule.get('href') + '.html'\n",
    "            \n",
    "            try:                \n",
    "                with open(url_cal, encoding=\"utf-8\") as f:\n",
    "                    data_cal = f.read()\n",
    "                    soup_cal = BeautifulSoup(data_cal, 'html.parser')\n",
    "\n",
    "                shows = soup_cal.find_all('b')[8:]\n",
    "                for show in shows:\n",
    "                    info = []\n",
    "                    info.append(country)\n",
    "                    info.append(city)\n",
    "                    info.append(theatre)                            \n",
    "                    info.append(show.text)\n",
    "                    link = show.parent.parent.parent.find('a').get('href')\n",
    "                    info.append(link.split(\"date=\")[-1])                \n",
    "                    try:\n",
    "                        composer_key = process.extract(show.text, list(map_dict.keys()), limit=1)\n",
    "                        composer_key = composer_key[0][0]\n",
    "                        composer = map_dict.get(composer_key)\n",
    "                    except:\n",
    "                        composer = ''                \n",
    "                    info.append(composer)\n",
    "                    listings.append(info)        \n",
    "            except:\n",
    "                print(url_cal)\n",
    "                    \n",
    "\n",
    "import pandas as pd                     \n",
    "headers = ['country', 'city', 'theatre', 'work', 'date', 'composer']\n",
    "df = pd.DataFrame(listings, columns=headers)\n",
    "df.to_csv('../../data/processed/listings/operabase_2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
