{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests, csv, string, re, datetime\n",
    "from csv import writer\n",
    "import time\n",
    "import random\n",
    "\n",
    "headers = { 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36'}\n",
    "cookies = dict(PHPSESSID='hu3bbnbkj9pjhm2h5ls52r5aa0', collections='audio_tech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_archive(url, base_url, season, offset):\n",
    "    r  = requests.get(url, headers=headers)\n",
    "#     print(1)    \n",
    "    soup = BeautifulSoup(r.text, \"html5lib\")    \n",
    "    countries =[]\n",
    "    \n",
    "    for l in soup.select('table a'):\n",
    "        if 'plan.cgi?lang=en&season=' in l.get('href') and '&ci=':\n",
    "            country = []\n",
    "            country.append(l.text)\n",
    "            country.append(l.get('href'))        \n",
    "            countries.append(country)\n",
    "        \n",
    "    listings = []\n",
    "    countries = countries[offset:]\n",
    "#     print(countries)\n",
    "    for c in countries:    \n",
    "        print(c[0])\n",
    "        url = base_url + c[1]\n",
    "        country = c[0]\n",
    "        r  = requests.get(url, headers=headers)\n",
    "#         print(2)            \n",
    "        soup = BeautifulSoup(r.text, \"html5lib\")\n",
    "        schedules = soup.find_all('a')\n",
    "        schedules = [s for s in schedules if 'view.cgi?lang=en&cal=' in s.get('href')]\n",
    "        for idx,schedule in enumerate(schedules):\n",
    "\n",
    "            map_dict = {}        \n",
    "            try:   \n",
    "                if idx!=0:\n",
    "                    items = schedule.next_sibling.next_sibling.find_all('a')\n",
    "                else:\n",
    "                    items = schedule.parent.next_sibling.find_all('a')\n",
    "                    \n",
    "                for item in items:\n",
    "                    work = item.get_text()\n",
    "                    composer = re.search('\\((.*?)\\)', item.parent.next_sibling).group(0)[1:-1]\n",
    "                    map_dict[work]=composer\n",
    "                map_dict            \n",
    "            except:\n",
    "                None\n",
    "                \n",
    "                \n",
    "            city = schedule.previous_sibling.previous_sibling.find('b').text\n",
    "            theatre = ','.join(schedule.previous_sibling.previous_sibling.text.split(',')[1:]).strip()        \n",
    "            url_cal = base_url + schedule.get('href')\n",
    "            r_cal  = requests.get(url_cal, headers=headers)\n",
    "#             print(3)\n",
    "\n",
    "            time.sleep(3)\n",
    "    \n",
    "            soup_cal = BeautifulSoup(r_cal.text, \"html5lib\")\n",
    "            shows = soup_cal.find_all('b')[8:]\n",
    "            for show in shows:\n",
    "                info = []\n",
    "                info.append(country)\n",
    "                info.append(city)\n",
    "                info.append(theatre)                            \n",
    "                info.append(show.text)\n",
    "                link = show.parent.parent.parent.find('a').get('href')\n",
    "                date = link.split(\"date=\")[-1]\n",
    "                info.append(date)\n",
    "                \n",
    "                try:\n",
    "                    composer = map_dict.get(show.text)\n",
    "                except:\n",
    "                    composer = ''\n",
    "                \n",
    "                info.append(composer)  \n",
    "#                 print(map_dict)\n",
    "#                 print(info)\n",
    "                listings.append(info)\n",
    "\n",
    "#     return listings\n",
    "#     print()\n",
    "    with open('operabase_archive_' + season + '.csv', 'w') as outfile:\n",
    "        mywriter = writer(outfile)\n",
    "        mywriter.writerow(['country', 'city', 'theatre', 'work', 'date', 'composer'])\n",
    "        for work in listings:\n",
    "            mywriter.writerow(work) \n",
    "        print('completed: ' + season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####### URL #########\n",
    "# get_archive('https://web.archive.org/web/20120510091223/http://operabase.com/plan.cgi?lang=en&season=2011/12', \\\n",
    "#             'https://web.archive.org/web/20120510091223/http://operabase.com/', '1112', 3)\n",
    "# get_archive('https://web.archive.org/web/20130223084132/http://www.operabase.com/plan.cgi?lang=en&season=2012/13', \\\n",
    "#             'https://web.archive.org/web/20130223084132/http://www.operabase.com/', '1213', 1)\n",
    "# get_archive('https://web.archive.org/web/20140729224252/http://operabase.com:80/plan.cgi?lang=en&season=2013/14', \\\n",
    "#             'https://web.archive.org/web/20140729224252/http://operabase.com:80/', '1314', 2)\n",
    "# get_archive('https://web.archive.org/web/20150924162245/http://operabase.com:80/plan.cgi?lang=en&season=2014/15', \\\n",
    "#             'https://web.archive.org/web/20150924162245/http://operabase.com:80/', '1415', 1)\n",
    "# get_archive('https://web.archive.org/web/20150905064133/http://operabase.com/plan.cgi?lang=en&season=2015/16', \\\n",
    "#             'https://web.archive.org/web/20150905064133/http://operabase.com/', '1516', 1)\n",
    "# get_archive('https://web.archive.org/web/20160307032948/http://operabase.com/plan.cgi?lang=en&season=2015/16', \\\n",
    "#             'https://web.archive.org/web/20160307032948/http://operabase.com/', '1516', 1)\n",
    "# get_archive('http://operabase.com/plan.cgi?lang=en&season=2016/17', 'http://operabase.com/', '1617', 1)\n",
    "# get_archive('http://operabase.com/plan.cgi?lang=en&season=2017/18', 'http://operabase.com/', '1718', 1)\n",
    "# get_archive('http://operabase.com/plan.cgi?lang=en&season=2018/19', 'http://operabase.com/', '1819', 1)\n",
    "\n",
    "#maybe?\n",
    "# 'https://web.archive.org/web/20110703001443/http://operabase.com/plan.cgi?lang=en&season=2010/11&ci='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = schedules[0].next_sibling.next_sibling.find_all('a')\n",
    "map_dict = {}\n",
    "for item in items:\n",
    "    work = item.get_text()\n",
    "    composer = re.search('\\((.*?)\\)', item.parent.next_sibling).group(0)[1:-1]\n",
    "    map_dict[work]=composer\n",
    "#     print(re.search('\\((.*?)\\)', item.parent.next_sibling).group(0)[1:-1])\n",
    "map_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests, csv, string, re, datetime\n",
    "from csv import writer\n",
    "\n",
    "url = 'https://web.archive.org/web/20120524150522/http://operabase.com/plan.cgi?lang=en&season=2011/12&ci=at'\n",
    "r  = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, \"html5lib\")\n",
    "schedules = soup.find_all('a')\n",
    "schedules = [s for s in schedules if 'view.cgi?lang=en&cal=' in s.get('href')]\n",
    "# for schedule in schedules:\n",
    "#     city = schedule.previous_sibling.previous_sibling.find('b').text\n",
    "#     theatre = ','.join(schedule.previous_sibling.previous_sibling.text.split(',')[1:]).strip()        \n",
    "#     url_cal = base_url + schedule.get('href')\n",
    "# #             print(url_cal)            \n",
    "#     r_cal  = requests.get(url_cal)\n",
    "#     soup_cal = BeautifulSoup(r_cal.text, \"html5lib\")\n",
    "#     shows = soup_cal.find_all('b')[8:]\n",
    "#     for show in shows:\n",
    "#         info = []\n",
    "#         info.append(country)\n",
    "#         info.append(city)\n",
    "#         info.append(theatre)                            \n",
    "#         info.append(show.text)\n",
    "#         link = show.parent.parent.parent.find('a').get('href')\n",
    "#         date = link.split(\"date=\")[-1]\n",
    "#         info.append(date)\n",
    "#         listings.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
