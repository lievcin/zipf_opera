{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests, csv, string, re\n",
    "from csv import writer\n",
    "\n",
    "abc = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "abc = list(abc)\n",
    "base_url = 'https://www.uktw.co.uk/archive/work/opera/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(listings):\n",
    "    rows = listings.find_all('tr')\n",
    "    venue, from_date, to_date, company, composer, when_dates, town = ('','','','','','','')\n",
    "    for row in rows:\n",
    "        if venue == '':\n",
    "            try:\n",
    "                venue = row.find(\"b\", string=\"Venue\").parent.parent.text.replace('Venue', '')\n",
    "            except:\n",
    "                None\n",
    "        if from_date == '':\n",
    "            try:\n",
    "                from_date = row.find(\"b\", string=\"From\").parent.parent.text.replace('From', '')\n",
    "            except:\n",
    "                None\n",
    "        if to_date == '':\n",
    "            try:\n",
    "                to_date = row.find(\"b\", string=\"To\").parent.parent.text.replace('To', '')\n",
    "            except:\n",
    "                None      \n",
    "        if company == '':\n",
    "            try:\n",
    "                company = row.find(\"b\", text=re.compile(\"Company(.*)\")).parent.parent.text.replace('Company', '').strip()\n",
    "            except:\n",
    "                None      \n",
    "            try:\n",
    "                company = row.find(\"b\", text=re.compile(\"Producer(.*)\")).parent.parent.text.replace('Producer', '').strip()\n",
    "            except:\n",
    "                None\n",
    "            try:\n",
    "                company = row.find(\"b\", text=re.compile(\"Presented by(.*)\")).parent.parent.text.replace('Presented by', '').strip()\n",
    "            except:\n",
    "                None                   \n",
    "        if composer == '':\n",
    "            try:\n",
    "                composer = row.find(\"b\", text=re.compile(\"Music(.*)\")).parent.parent.text.replace('Music', '').strip()                \n",
    "            except:\n",
    "                None  \n",
    "            try:\n",
    "                composer = row.find(\"b\", text=re.compile(\"Author(.*)\")).parent.parent.text.replace('Author', '').strip()                \n",
    "            except:\n",
    "                None       \n",
    "        if when_dates == '':\n",
    "            try:\n",
    "                when_dates = row.find(\"b\", text=re.compile(\"When(.*)\")).parent.parent.text.replace('When', '').strip()                \n",
    "            except:\n",
    "                None  \n",
    "        if town == '':\n",
    "            try:\n",
    "                town = row.find(\"b\", text=re.compile(\"Town(.*)\")).parent.parent.text.replace('Town', '').strip()                \n",
    "            except:\n",
    "                None                  \n",
    "    return venue, from_date, to_date, company, composer, when_dates, town\n",
    "\n",
    "def get_more_info(listings):\n",
    "    category = 'live'\n",
    "    details = listings.find('h2', text='Production details')\n",
    "    if details:\n",
    "        if len(details.parent.find_all(text = re.compile('Broadcast'))) > 0:\n",
    "            category = 'broadcast'\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "C\n",
      "D\n",
      "E\n",
      "F\n",
      "G\n",
      "H\n",
      "I\n",
      "J\n",
      "K\n",
      "L\n",
      "M\n",
      "N\n",
      "O\n",
      "P\n",
      "Q\n",
      "R\n",
      "S\n",
      "T\n",
      "U\n",
      "V\n",
      "W\n",
      "X\n",
      "Y\n",
      "Z\n"
     ]
    }
   ],
   "source": [
    "shows= []\n",
    "for l in abc:\n",
    "    print(l)\n",
    "    url = base_url + l\n",
    "    r  = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"html5lib\")\n",
    "    codes = soup.find_all('ul')[10].find_all('li')\n",
    "    for code in codes:        \n",
    "        opera_name = code.text.strip()\n",
    "        link = code.find('a').get('href')\n",
    "        r_show  = requests.get(link)\n",
    "        listings = BeautifulSoup(r_show.text, \"html5lib\")\n",
    "        for i in listings.find_all('i'):\n",
    "            if len(i.find_all('a')) > 0:\n",
    "                if i.find('a').get('href') != None:             \n",
    "                    show = []\n",
    "                    show.append(opera_name)\n",
    "                    show.append(i.find('a').get('href'))\n",
    "                    shows.append(show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n"
     ]
    }
   ],
   "source": [
    "listings = []\n",
    "\n",
    "for idx, show in enumerate(shows):\n",
    "    if idx%1000==0:\n",
    "        print(idx)\n",
    "        \n",
    "    if show[1] != '':\n",
    "        try:\n",
    "            r  = requests.get(show[1])\n",
    "            soup = BeautifulSoup(r.text, \"html5lib\")\n",
    "            work = show[0]\n",
    "            venue, from_date, to_date, company, composer, when_dates, town  = get_info(soup)\n",
    "            category = get_more_info(soup)\n",
    "            listing = []\n",
    "            listing.append(work)            \n",
    "            listing.append(venue)\n",
    "            listing.append(town)\n",
    "            listing.append(from_date)\n",
    "            listing.append(to_date)\n",
    "            listing.append(company)\n",
    "            listing.append(composer)        \n",
    "            listing.append(when_dates)         \n",
    "            listing.append(category)\n",
    "            listing.append(show[1])            \n",
    "            listings.append(listing)\n",
    "        except:\n",
    "            None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "headers = ['work', 'venue', 'town', 'from', 'to', 'company', 'composer', 'dates', 'category', 'url']\n",
    "df = pd.DataFrame(listings, columns=headers)\n",
    "df.to_csv('../../data/raw/uktw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "import math\n",
    "\n",
    "months_l = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "days_l = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', \n",
    "        '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', \n",
    "        '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', \n",
    "        '31', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "def fix_date(date):\n",
    "    try:\n",
    "        date_1 = re.sub('\\d+(st|nd|rd|th)', lambda m: m.group()[:-2].zfill(2), date)    \n",
    "        date_1 = datetime.strptime(date_1, '%d %B %Y').date()\n",
    "    except:\n",
    "        print(date)    \n",
    "    \n",
    "    return date_1\n",
    "\n",
    "# def get_num_performances(row):\n",
    "#     if row['date_from']==row['date_to']:\n",
    "#         NPERFORM = 1\n",
    "#     else:\n",
    "#         days = (row['date_to']-row['date_from']).days\n",
    "#         if days <= 3:\n",
    "#             NPERFORM = days\n",
    "#         elif re.search(r\"([01]?[0-9]|2[0-3]):[0-5][0-9]\", row['dates']):\n",
    "#             hours = re.search(r\"([01]?[0-9]|2[0-3]):[0-5][0-9]\", row['dates']).group(0)\n",
    "#             if hours==row['dates']:\n",
    "#                 NPERFORM = days\n",
    "#             else:\n",
    "#                 dates = re.sub(r\" at ([01]?[0-9]|2[0-3]):[0-5][0-9]\", '', row['dates'])\n",
    "#                 dates = re.split('\\.|,| |\\*|\\n', dates)\n",
    "#                 days_in_sentence = [x for x in dates if x in days_l]\n",
    "#                 if len(days_in_sentence) > 0:\n",
    "#                     NPERFORM = len(days_in_sentence)\n",
    "#                 elif days <=30:\n",
    "#                     NPERFORM = min([math.ceil(days/1.5),10])\n",
    "#                 elif days <=60:\n",
    "#                     NPERFORM = min([math.ceil(days/4.),15])\n",
    "#                 elif days >60:\n",
    "#                     NPERFORM = 15\n",
    "#         else:\n",
    "#             if days <=30:\n",
    "#                 NPERFORM = min([math.ceil(days/1.5),10])\n",
    "#             elif days <=60:\n",
    "#                 NPERFORM = min([math.ceil(days/4.),15])\n",
    "#             elif days >60:\n",
    "#                 NPERFORM = 15                    \n",
    "#     return NPERFORM\n",
    "\n",
    "def get_num_performances(row):\n",
    "    if row['date_from']==row['date_to']:\n",
    "        NPERFORM = 1\n",
    "    else:\n",
    "        days = (row['date_to']-row['date_from']).days + 1\n",
    "        if days <= 3:\n",
    "            NPERFORM = days\n",
    "        elif re.search(r\"([01]?[0-9]|2[0-3]):[0-5][0-9]\", row['dates']):\n",
    "            hours = re.search(r\"([01]?[0-9]|2[0-3]):[0-5][0-9]\", row['dates']).group(0)\n",
    "            dates = re.sub(r\" at ([01]?[0-9]|2[0-3]):[0-5][0-9]\", '', row['dates'])\n",
    "            dates = re.split('\\.|,| |\\*|\\n', dates)\n",
    "            days_in_sentence = [x for x in dates if x in days_l]\n",
    "            if len(days_in_sentence) > 0:\n",
    "                NPERFORM = len(days_in_sentence)\n",
    "            elif days <=30:\n",
    "                NPERFORM = min([math.ceil(days/1.5),10])\n",
    "            elif days <=60:\n",
    "                NPERFORM = min([math.ceil(days/4.),15])\n",
    "            elif days >60:\n",
    "                NPERFORM = 15\n",
    "        else:\n",
    "            if days <=30:\n",
    "                NPERFORM = min([math.ceil(days/1.5),10])\n",
    "            elif days <=60:\n",
    "                NPERFORM = min([math.ceil(days/4.),15])\n",
    "            elif days >60:\n",
    "                NPERFORM = 15\n",
    "    return NPERFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load and finish the df.\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../../data/raw/uktw.csv', index_col=0)\n",
    "df['from'].fillna(df['to'], inplace=True)\n",
    "df['date_from'] = df.apply(lambda row: fix_date(row['from']), axis=1)\n",
    "df['date_to'] = df.apply(lambda row: fix_date(row['to']), axis=1)\n",
    "df['dates'].fillna('', inplace=True)\n",
    "df['num_performances'] = df.apply(lambda row: get_num_performances(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_column_names = ['work', 'composer', 'venue', 'town', 'company', 'date_from', 'date_to', 'num_performances', 'url']\n",
    "df = df[output_column_names]\n",
    "df.to_csv('../../data/processed/listings/uk_theatreweb.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
